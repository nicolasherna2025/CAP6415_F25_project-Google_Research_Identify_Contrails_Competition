{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e362f5e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T14:55:46.112623Z",
     "iopub.status.busy": "2025-12-08T14:55:46.112061Z",
     "iopub.status.idle": "2025-12-08T14:55:51.303124Z",
     "shell.execute_reply": "2025-12-08T14:55:51.302545Z"
    },
    "papermill": {
     "duration": 5.196159,
     "end_time": "2025-12-08T14:55:51.304505",
     "exception": false,
     "start_time": "2025-12-08T14:55:46.108346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdcdefa",
   "metadata": {
    "papermill": {
     "duration": 0.002503,
     "end_time": "2025-12-08T14:55:51.309751",
     "exception": false,
     "start_time": "2025-12-08T14:55:51.307248",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9d69c0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T14:55:51.315414Z",
     "iopub.status.busy": "2025-12-08T14:55:51.315086Z",
     "iopub.status.idle": "2025-12-08T14:55:51.406847Z",
     "shell.execute_reply": "2025-12-08T14:55:51.406239Z"
    },
    "papermill": {
     "duration": 0.095963,
     "end_time": "2025-12-08T14:55:51.408059",
     "exception": false,
     "start_time": "2025-12-08T14:55:51.312096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Weights dataset \n",
    "WEIGHTS_PATH = \"/kaggle/input/cap6415-contrail-weights/best_model.pth\" \n",
    "# Competition test dataset\n",
    "DATA_DIR = Path('/kaggle/input/google-research-identify-contrails-reduce-global-warming')\n",
    "TEST_DIR = DATA_DIR / 'test'\n",
    "BATCH_SIZE = 4 \n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Constants\n",
    "T11_BOUNDS = (243, 303)\n",
    "CLOUD_TOP_TDIFF_BOUNDS = (-4, 5)\n",
    "TDIFF_BOUNDS = (-4, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5dbc95",
   "metadata": {
    "papermill": {
     "duration": 0.002309,
     "end_time": "2025-12-08T14:55:51.413153",
     "exception": false,
     "start_time": "2025-12-08T14:55:51.410844",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Ash color functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2573b1b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T14:55:51.419319Z",
     "iopub.status.busy": "2025-12-08T14:55:51.418642Z",
     "iopub.status.idle": "2025-12-08T14:55:51.422782Z",
     "shell.execute_reply": "2025-12-08T14:55:51.422308Z"
    },
    "papermill": {
     "duration": 0.008284,
     "end_time": "2025-12-08T14:55:51.423813",
     "exception": false,
     "start_time": "2025-12-08T14:55:51.415529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bounds for Ash Color Scheme\n",
    "_T11_BOUNDS = (243, 303)\n",
    "_CLOUD_TOP_TDIFF_BOUNDS = (-4, 5)\n",
    "_TDIFF_BOUNDS = (-4, 2)\n",
    "\n",
    "# Normalization function for Ash Color Scheme\n",
    "def normalize_range(data, bounds):\n",
    "    \"\"\"Maps data to the range [0, 1].\"\"\"\n",
    "    return (data - bounds[0]) / (bounds[1] - bounds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c3a0f9",
   "metadata": {
    "papermill": {
     "duration": 0.002026,
     "end_time": "2025-12-08T14:55:51.428162",
     "exception": false,
     "start_time": "2025-12-08T14:55:51.426136",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd1d5a60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T14:55:51.433170Z",
     "iopub.status.busy": "2025-12-08T14:55:51.432986Z",
     "iopub.status.idle": "2025-12-08T14:55:51.438717Z",
     "shell.execute_reply": "2025-12-08T14:55:51.438157Z"
    },
    "papermill": {
     "duration": 0.009473,
     "end_time": "2025-12-08T14:55:51.439734",
     "exception": false,
     "start_time": "2025-12-08T14:55:51.430261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ContrailDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads the sequences, calculates Ash Color Scheme, and returns 3D tensors.\n",
    "    Input Shape: (H, W, T) from numpy files.\n",
    "    Output Shape: (C, T, H, W) for PyTorch 3D Conv.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir, record_ids):\n",
    "        self.root = Path(data_dir) \n",
    "        self.record_ids = list(record_ids)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.record_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rid = self.record_ids[idx]\n",
    "        rid_path = self.root / rid\n",
    "\n",
    "        # Load Bands (Shape: 256, 256, 8)\n",
    "        band11 = np.load(rid_path / \"band_11.npy\").astype(np.float32)\n",
    "        band14 = np.load(rid_path / \"band_14.npy\").astype(np.float32)\n",
    "        band15 = np.load(rid_path / \"band_15.npy\").astype(np.float32)\n",
    "\n",
    "        # Calculate Ash Color Scheme\n",
    "        # R = Band 15 - Band 14\n",
    "        r = normalize_range(band15 - band14, _TDIFF_BOUNDS)\n",
    "        # G = Band 14 - Band 11\n",
    "        g = normalize_range(band14 - band11, _CLOUD_TOP_TDIFF_BOUNDS)\n",
    "        # B = Band 14\n",
    "        b = normalize_range(band14, _T11_BOUNDS)\n",
    "\n",
    "        # Stack to (3, 256, 256, 8)\n",
    "        rgb = np.stack([r, g, b], axis=0)\n",
    "        rgb = np.clip(rgb, 0, 1)\n",
    "\n",
    "        # Transpose from (C, H, W, T) to (C, T, H, W)\n",
    "        rgb = np.transpose(rgb, (0, 3, 1, 2)) \n",
    "\n",
    "        return torch.from_numpy(rgb), rid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4a21e2",
   "metadata": {
    "papermill": {
     "duration": 0.002131,
     "end_time": "2025-12-08T14:55:51.443976",
     "exception": false,
     "start_time": "2025-12-08T14:55:51.441845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e076a090",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T14:55:51.449976Z",
     "iopub.status.busy": "2025-12-08T14:55:51.449772Z",
     "iopub.status.idle": "2025-12-08T14:55:51.466573Z",
     "shell.execute_reply": "2025-12-08T14:55:51.466053Z"
    },
    "papermill": {
     "duration": 0.021215,
     "end_time": "2025-12-08T14:55:51.467581",
     "exception": false,
     "start_time": "2025-12-08T14:55:51.446366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sigle Convolution Long Short-Term Memory\n",
    "class ConvLSTMCell(nn.Module):\n",
    "    \"\"\"\n",
    "    A single step of ConvLSTM\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels, hidden_channels, kernel_size=3):\n",
    "        \"\"\"\n",
    "        Initialize ConvLSTM cell\n",
    "\n",
    "        input_channels (int): Number of channels of input tensor.  \n",
    "        hidden_channels (int): Number of channels of hidden state.   \n",
    "        kernel_size (int): Size of the convolutional kernel.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Initialize\n",
    "        self.input_channels = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        padding = kernel_size // 2\n",
    "        # Compute input, forget, cell, and output gates\n",
    "        self.conv = nn.Conv2d(input_channels + hidden_channels, 4 * hidden_channels, kernel_size, padding=padding)\n",
    "\n",
    "    def forward(self, x, h, c):\n",
    "        \"\"\"\n",
    "        x: (B, C_in, H, W)\n",
    "        h, c: (B, C_hidden, H, W)\n",
    "        returns: h_next, c_next\n",
    "        \"\"\"\n",
    "        # Concatenate input and previous hidden state along channel axis\n",
    "        combined = torch.cat([x, h], dim=1)\n",
    "        # Convolution \n",
    "        gates = self.conv(combined)\n",
    "        # Split into input gate, forget gate, candidate, output gate\n",
    "        i, f, g, o = torch.chunk(gates, 4, dim=1)\n",
    "        # Nonlinearities\n",
    "        i = torch.sigmoid(i)\n",
    "        f = torch.sigmoid(f)\n",
    "        g = torch.tanh(g)\n",
    "        o = torch.sigmoid(o)\n",
    "        # Update\n",
    "        c_next = f * c + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "        return h_next, c_next\n",
    "\n",
    "class ConvLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Full ConvLSTM using ConvLSTMCell\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels, hidden_channels, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.cell = ConvLSTMCell(input_channels, hidden_channels, kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (Batch, Channel, Time, Height, Width)\n",
    "        \"\"\"\n",
    "        B, C, T, H, W = x.shape\n",
    "        # Initial h and c \n",
    "        h = torch.zeros(B, self.cell.hidden_channels, H, W, device=x.device)\n",
    "        c = torch.zeros(B, self.cell.hidden_channels, H, W, device=x.device)\n",
    "        \n",
    "        outputs = []\n",
    "        # Loop through each time step\n",
    "        for t in range(T):\n",
    "            # time step\n",
    "            x_t = x[:, :, t, :, :] \n",
    "            # One step of ConvLSTMCell\n",
    "            h, c = self.cell(x_t, h, c)\n",
    "            # add time dimension back (B, C, 1, H, W)\n",
    "            outputs.append(h.unsqueeze(2)) \n",
    "            \n",
    "        # Concatenate along time axis\n",
    "        return torch.cat(outputs, dim=2), (h, c)\n",
    "\n",
    "# Code from Wen, Q. (2020). ConvLSTM PyTorch implementation [Code repository]. GitHub.\n",
    "# https://github.com/ndrplz/ConvLSTM_pytorch\n",
    "\n",
    "class Conv3DBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Standard 3D Convolution Block\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            # First 3×3×3 conv\n",
    "            nn.Conv3d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # Second 3×3×3 conv\n",
    "            nn.Conv3d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x): return self.block(x)\n",
    "\n",
    "# Main model\n",
    "class UNet3D_ConvLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    3D U-Net + ConvLSTM bottleneck.\n",
    "    Input:  x  (B, C=3, T=8, H=256, W=266)\n",
    "    Output: (B, 1, H, W) binary mask\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=3, base_channels=16):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc1 = Conv3DBlock(in_channels, base_channels)\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=(1, 2, 2)) \n",
    "        \n",
    "        self.enc2 = Conv3DBlock(base_channels, base_channels*2)\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=(1, 2, 2))\n",
    "        \n",
    "        self.enc3 = Conv3DBlock(base_channels*2, base_channels*4)\n",
    "        self.pool3 = nn.MaxPool3d(kernel_size=(1, 2, 2))\n",
    "        \n",
    "        # ConvLSTM Bottle neck\n",
    "        # Input: (B, 64, 8, 32, 32)\n",
    "        self.proj = nn.Conv3d(base_channels*4, base_channels*4, kernel_size=1)\n",
    "        self.lstm = ConvLSTM(base_channels*4, base_channels*8, kernel_size=3)\n",
    "        \n",
    "        # Decoder (Expanding Path)\n",
    "        self.up3 = nn.ConvTranspose3d(base_channels*8, base_channels*4, kernel_size=(1,2,2), stride=(1,2,2))\n",
    "        self.dec3 = Conv3DBlock(base_channels*8, base_channels*4)\n",
    "        \n",
    "        self.up2 = nn.ConvTranspose3d(base_channels*4, base_channels*2, kernel_size=(1,2,2), stride=(1,2,2))\n",
    "        self.dec2 = Conv3DBlock(base_channels*4, base_channels*2)\n",
    "        \n",
    "        self.up1 = nn.ConvTranspose3d(base_channels*2, base_channels, kernel_size=(1,2,2), stride=(1,2,2))\n",
    "        self.dec1 = Conv3DBlock(base_channels*2, base_channels)\n",
    "        \n",
    "        # Head\n",
    "        self.final = nn.Conv3d(base_channels, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, 3, 8, 256, 256)\n",
    "        \n",
    "        # Encoder\n",
    "        e1 = self.enc1(x) # (16, 8, 256, 256)\n",
    "        p1 = self.pool1(e1) # (16, 8, 128, 128)\n",
    "        \n",
    "        e2 = self.enc2(p1) # (32, 8, 128, 128)\n",
    "        p2 = self.pool2(e2) # (32, 8, 64, 64)\n",
    "        \n",
    "        e3 = self.enc3(p2) # (64, 8, 64, 64)\n",
    "        p3 = self.pool3(e3) # (64, 8, 32, 32)\n",
    "        \n",
    "        # Bottleneck\n",
    "        p3 = self.proj(p3)\n",
    "        lstm_out, _ = self.lstm(p3) # (128, 8, 32, 32)\n",
    "        \n",
    "        # Decoder\n",
    "        u3 = self.up3(lstm_out) # (64, 8, 64, 64)\n",
    "        cat3 = torch.cat([u3, e3], dim=1) # Skip connection\n",
    "        d3 = self.dec3(cat3)\n",
    "        \n",
    "        u2 = self.up2(d3) # (32, 8, 128, 128)\n",
    "        cat2 = torch.cat([u2, e2], dim=1) # Skip connection\n",
    "        d2 = self.dec2(cat2)\n",
    "        \n",
    "        u1 = self.up1(d2) # (16, 8, 256, 256)\n",
    "        cat1 = torch.cat([u1, e1], dim=1) # Skip connection\n",
    "        d1 = self.dec1(cat1)\n",
    "        \n",
    "        # Final Projection\n",
    "        out_3d = self.final(d1) # (B, 1, 8, 256, 256)\n",
    "        \n",
    "        # Select the labeld image (5th image)\n",
    "        out_2d = out_3d[:, :, 4, :, :] \n",
    "        \n",
    "        return out_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0688b4",
   "metadata": {
    "papermill": {
     "duration": 0.002027,
     "end_time": "2025-12-08T14:55:51.471673",
     "exception": false,
     "start_time": "2025-12-08T14:55:51.469646",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### RLE functions for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f0d4553",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T14:55:51.476581Z",
     "iopub.status.busy": "2025-12-08T14:55:51.476386Z",
     "iopub.status.idle": "2025-12-08T14:55:51.480914Z",
     "shell.execute_reply": "2025-12-08T14:55:51.480388Z"
    },
    "papermill": {
     "duration": 0.00814,
     "end_time": "2025-12-08T14:55:51.481892",
     "exception": false,
     "start_time": "2025-12-08T14:55:51.473752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rle_encode(x, fg_val=1):\n",
    "    \"\"\"\n",
    "    Encoding for submission.\n",
    "    x (numpy array): mask (1=contrail, 0=bg)\n",
    "    Returns: list of run lengths\n",
    "    \"\"\"\n",
    "    # 1d array with that finds the indices of pixels where there are contrails\n",
    "    dots = np.where(x.T.flatten() == fg_val)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2 # Because indices start at 0\n",
    "    for b in dots:\n",
    "        # Check if the current pixel is not the neighbor of the previous pixel\n",
    "        if b > prev + 1:\n",
    "            # Add start position\n",
    "            run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b # update\n",
    "    return run_lengths\n",
    "\n",
    "def list_to_string(x):\n",
    "    \"\"\"\n",
    "    Converts RLE list to string for CSV\n",
    "    \"\"\"\n",
    "    if x:\n",
    "        s = str(x).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\")\n",
    "    else:\n",
    "        s = '-'\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8914352",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T14:55:51.486764Z",
     "iopub.status.busy": "2025-12-08T14:55:51.486578Z",
     "iopub.status.idle": "2025-12-08T14:55:51.492714Z",
     "shell.execute_reply": "2025-12-08T14:55:51.492169Z"
    },
    "papermill": {
     "duration": 0.00973,
     "end_time": "2025-12-08T14:55:51.493669",
     "exception": false,
     "start_time": "2025-12-08T14:55:51.483939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_inference():\n",
    "    print(\"Loading Model...\")\n",
    "    # Load model\n",
    "    model = UNet3D_ConvLSTM(in_channels=3, base_channels=16).to(DEVICE)\n",
    "    \n",
    "    # Load Weights\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(WEIGHTS_PATH, map_location=DEVICE))\n",
    "        print(\"Weights loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading weights: {e}\")\n",
    "        print(\"Make sure you are pointing to the correct .pth file in your input dataset.\")\n",
    "        return\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    print(\"Preparing Data...\")\n",
    "    if not os.path.exists(TEST_DIR):\n",
    "        print(\"Test directory not found, skipping.\")\n",
    "        return\n",
    "\n",
    "    test_ids = sorted(os.listdir(TEST_DIR))\n",
    "    test_ds = ContrailDataset(TEST_DIR, test_ids)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "    \n",
    "    submission_data = []\n",
    "    \n",
    "    print(\"Starting Prediction...\")\n",
    "    with torch.no_grad():\n",
    "        for x, rids in tqdm(test_loader):\n",
    "            x = x.to(DEVICE)\n",
    "            logits = model(x)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            \n",
    "            # Thresholding\n",
    "            preds = (probs > 0.5).float().cpu().numpy()[:, 0, :, :]\n",
    "            \n",
    "            for i, rid in enumerate(rids):\n",
    "                mask = preds[i]\n",
    "                rle = rle_encode(mask)\n",
    "                rle_str = list_to_string(rle)\n",
    "                submission_data.append({\"record_id\": rid, \"encoded_pixels\": rle_str})\n",
    "                \n",
    "    df_sub = pd.DataFrame(submission_data)\n",
    "    df_sub.to_csv(\"submission.csv\", index=False)\n",
    "    print(\"submission.csv generated successfully!\")\n",
    "    print(df_sub.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49e6cb98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-08T14:55:51.498608Z",
     "iopub.status.busy": "2025-12-08T14:55:51.498437Z",
     "iopub.status.idle": "2025-12-08T14:55:53.005523Z",
     "shell.execute_reply": "2025-12-08T14:55:53.004727Z"
    },
    "papermill": {
     "duration": 1.510868,
     "end_time": "2025-12-08T14:55:53.006638",
     "exception": false,
     "start_time": "2025-12-08T14:55:51.495770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model...\n",
      "Weights loaded successfully!\n",
      "Preparing Data...\n",
      "Starting Prediction...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bba40efb44140edb2b53031ab3b04ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission.csv generated successfully!\n",
      "             record_id                                   encoded_pixels\n",
      "0  1000834164244036115  41223 2 41480 3 41737 4 41995 4 42252 4 42511 2\n",
      "1  1002653297254493116                                                -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "run_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2f9243",
   "metadata": {
    "papermill": {
     "duration": 0.002494,
     "end_time": "2025-12-08T14:55:53.011814",
     "exception": false,
     "start_time": "2025-12-08T14:55:53.009320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 5692552,
     "isSourceIdPinned": false,
     "sourceId": 51753,
     "sourceType": "competition"
    },
    {
     "datasetId": 8946208,
     "sourceId": 14054365,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.550859,
   "end_time": "2025-12-08T14:55:54.234060",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-08T14:55:42.683201",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2f5a931aaa2042959ceb4c256e3b654a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "34b747e47bb14e98be0c77417c2389ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8c28c09c918a479facb44ae3f5e90b7b",
       "placeholder": "​",
       "style": "IPY_MODEL_99e0d83359e14ef5b51b11f61804237a",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "3ea07d7f768b4ca49e4771866b9fce15": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4bba40efb44140edb2b53031ab3b04ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_34b747e47bb14e98be0c77417c2389ad",
        "IPY_MODEL_c44a2cdb0ca749e6b49d6b49bdfa3fdb",
        "IPY_MODEL_ed47460dc9cf4b489ef6eca5bbafbc62"
       ],
       "layout": "IPY_MODEL_b84b28074b6c4c06868fc1881e6a2ff3",
       "tabbable": null,
       "tooltip": null
      }
     },
     "6f52f5dd24d1496db4ab4a52b020861c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8c28c09c918a479facb44ae3f5e90b7b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "99e0d83359e14ef5b51b11f61804237a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b08667c321a94070a229358a7a39d815": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b84b28074b6c4c06868fc1881e6a2ff3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c44a2cdb0ca749e6b49d6b49bdfa3fdb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b08667c321a94070a229358a7a39d815",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6f52f5dd24d1496db4ab4a52b020861c",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "ed47460dc9cf4b489ef6eca5bbafbc62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3ea07d7f768b4ca49e4771866b9fce15",
       "placeholder": "​",
       "style": "IPY_MODEL_2f5a931aaa2042959ceb4c256e3b654a",
       "tabbable": null,
       "tooltip": null,
       "value": " 1/1 [00:01&lt;00:00,  1.10s/it]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
